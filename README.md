Respository for RepliMaMMUT

To run in distributed training, call torchrun --standalone --nproc_per_node=gpu path_to_main_distributed.py